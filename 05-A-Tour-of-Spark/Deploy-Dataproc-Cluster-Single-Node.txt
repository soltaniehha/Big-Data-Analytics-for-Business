*******************************************
******* CREATE SINGLE-NODE CLUSTER ********
*******************************************
gcloud dataproc clusters create single-spark353 \
  --bucket <BUCKET-NAME> \
  --region us-central1 \
  --master-machine-type n2-highmem-4 \
  --master-boot-disk-type pd-standard \
  --master-boot-disk-size 30 \
  --single-node \
  --no-address \
  --image-version 2.2-debian12 \
  --optional-components JUPYTER \
  --initialization-actions gs://dataproc-initialization-actions/python/pip-install.sh \
  --metadata 'PIP_PACKAGES=google-cloud-storage' \
  --enable-component-gateway

****************************************************
******* CREATE SINGLE-NODE CLUSTER ONE-LINER *******
****************************************************
gcloud dataproc clusters create single-spark353 --bucket <BUCKET-NAME> --region us-central1 --master-machine-type n2-highmem-4 --master-boot-disk-type pd-standard --master-boot-disk-size 30 --single-node --no-address --image-version 2.2-debian12 --optional-components JUPYTER --initialization-actions gs://dataproc-initialization-actions/python/pip-install.sh --metadata 'PIP_PACKAGES=google-cloud-storage' --enable-component-gateway

**************************
******* SSH Tunnel *******
**************************
Select the cluster and under web interfaces select Jupyter or Jupyter Lab.
OR
gcloud compute ssh single-spark353-m --zone us-central1-X -- -L 8080:localhost:8123

Replace X with the actual assigned zone.

********************************
******* JUPYTER NOTEBOOK *******
********************************
localhost:8080

*********************************
******* TERMINATE CLUSTER *******
*********************************
gcloud dataproc clusters delete single-spark353 --region us-central1
