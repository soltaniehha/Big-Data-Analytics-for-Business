{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "\n",
    "Repeat the steps in notebook *11-Classification/02-Logistic-Regression-Example.ipynb* but with this new dataset. The data is located in *data/Telco-Customer-Churn.csv*. Please note that since you have most of the answers, 60% of the grade comes from the \"Next Steps\" section which is open ended. Use the knowledge and examples from the last 3 classes to explore different options and improve the algorithm. Finally, report your best model with its AUC on test and train.\n",
    "\n",
    "First part which is data importing and cleaning has been done for you.\n",
    "\n",
    "## Customer Churn\n",
    "\n",
    "Also known as customer attrition, or customer turnover is the loss of clients or customers. Customer churn is a critical metric because it is much less expensive to retain existing customers than it is to acquire new ones. \n",
    "\n",
    "Companies usually make a distinction between voluntary churn and involuntary churn. In most analyses involuntary churn is excluded. \n",
    "\n",
    "Predictive analytics uses machine learning to predict the likelihood of a customer churning. These models will identify a small subgroup of potential customers that are at a higher risk of abandoning the company. This empowers the company to focus on the subset of the customers who are most likely to churn and through customer retention marketing programs stop some of that to happen.\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "**Telco Customer Churn**\n",
    "\n",
    "The data was downloaded from IBM Sample Data Sets: https://www.ibm.com/communities/analytics/watson-analytics-blog/guide-to-sample-datasets/\n",
    "\n",
    "Each row represents a customer, each column contains customer's attributes described as below:\n",
    "\n",
    "* **customerID**: Customer ID\n",
    "* **gender**: Customer gender (female, male)\n",
    "* **SeniorCitizen**: Whether the customer is a senior citizen or not (1, 0)\n",
    "* **Partner**: Whether the customer has a partner or not (Yes, No)\n",
    "* **Dependents**: Whether the customer has dependents or not (Yes, No)\n",
    "* **tenure**: Number of months the customer has stayed with the company\n",
    "* **PhoneService**: Whether the customer has a phone service or not (Yes, No)\n",
    "* **MultipleLines**: Whether the customer has multiple lines or not (Yes, No, No phone service)\n",
    "* **InternetService**: Customer's internet service provider (DSL, Fiber optic, No)\n",
    "* **OnlineSecurity**: Whether the customer has online security or not (Yes, No, No internet service)\n",
    "* **OnlineBackup**: Whether the customer has online backup or not (Yes, No, No internet service)\n",
    "* **DeviceProtection**: Whether the customer has device protection or not (Yes, No, No internet service)\n",
    "* **TechSupport**: Whether the customer has tech support or not (Yes, No, No internet service)\n",
    "* **StreamingTV**: Whether the customer has streaming TV or not (Yes, No, No internet service)\n",
    "* **StreamingMovies**: Whether the customer has streaming movies or not (Yes, No, No internet service)\n",
    "* **Contract**: The contract term of the customer (Month-to-month, One year, Two year)\n",
    "* **PaperlessBilling**: Whether the customer has paperless billing or not (Yes, No)\n",
    "* **PaymentMethod**: The customer's payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))\n",
    "* **MonthlyCharges**: The amount charged to the customer monthly\n",
    "* **TotalCharges**: The total amount charged to the customer\n",
    "* **Churn**: Whether the customer churned or not (Yes or No)\n",
    "\n",
    "The data set includes information about:\n",
    "\n",
    "* Customers who left - the column is called `Churn`\n",
    "* Services that each customer has signed up for - phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n",
    "* Customer account information - how long they've been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n",
    "* Demographic info about customers - gender, age range, and if they have partners and dependents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://is843/notebooks/data/\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# the following line gets the bucket name attached to our cluster\n",
    "bucket = spark._jsc.hadoopConfiguration().get(\"fs.gs.system.bucket\")\n",
    "\n",
    "# specifying the path to our bucket where the data is located (no need to edit this path anymore)\n",
    "data = \"gs://\" + bucket + \"/notebooks/data/\"\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+-------+----------+------+------------+--------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
      "|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService| MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|      Contract|PaperlessBilling|       PaymentMethod|MonthlyCharges|TotalCharges|Churn|\n",
      "+------+-------------+-------+----------+------+------------+--------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
      "|Female|            0|    Yes|        No|     1|          No|NoPhoneService|            DSL|            No|         Yes|              No|         No|         No|             No|Month_to_month|             Yes|     ElectronicCheck|         29.85|       29.85|   No|\n",
      "|  Male|            0|     No|        No|    34|         Yes|            No|            DSL|           Yes|          No|             Yes|         No|         No|             No|       OneYear|              No|         MailedCheck|         56.95|      1889.5|   No|\n",
      "|  Male|            0|     No|        No|     2|         Yes|            No|            DSL|           Yes|         Yes|              No|         No|         No|             No|Month_to_month|             Yes|         MailedCheck|         53.85|      108.15|  Yes|\n",
      "|  Male|            0|     No|        No|    45|          No|NoPhoneService|            DSL|           Yes|          No|             Yes|        Yes|         No|             No|       OneYear|              No|BankTransferAutom...|          42.3|     1840.75|   No|\n",
      "|Female|            0|     No|        No|     2|         Yes|            No|     FiberOptic|            No|          No|              No|         No|         No|             No|Month_to_month|             Yes|     ElectronicCheck|          70.7|      151.65|  Yes|\n",
      "+------+-------------+-------+----------+------+------------+--------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- gender: string (nullable = true)\n",
      " |-- SeniorCitizen: integer (nullable = true)\n",
      " |-- Partner: string (nullable = true)\n",
      " |-- Dependents: string (nullable = true)\n",
      " |-- tenure: integer (nullable = true)\n",
      " |-- PhoneService: string (nullable = true)\n",
      " |-- MultipleLines: string (nullable = true)\n",
      " |-- InternetService: string (nullable = true)\n",
      " |-- OnlineSecurity: string (nullable = true)\n",
      " |-- OnlineBackup: string (nullable = true)\n",
      " |-- DeviceProtection: string (nullable = true)\n",
      " |-- TechSupport: string (nullable = true)\n",
      " |-- StreamingTV: string (nullable = true)\n",
      " |-- StreamingMovies: string (nullable = true)\n",
      " |-- Contract: string (nullable = true)\n",
      " |-- PaperlessBilling: string (nullable = true)\n",
      " |-- PaymentMethod: string (nullable = true)\n",
      " |-- MonthlyCharges: double (nullable = true)\n",
      " |-- TotalCharges: double (nullable = true)\n",
      " |-- Churn: string (nullable = true)\n",
      "\n",
      "This datasets consists of 7043 rows.\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .option(\"inferschema\", True)\\\n",
    "  .load(data + \"Telco-Customer-Churn.csv\")\\\n",
    "  .coalesce(5)\n",
    "\n",
    "df = df.drop('customerID')  # Dropping customerID\n",
    "df.cache()\n",
    "df.show(5)\n",
    "df.printSchema()\n",
    "print(\"This datasets consists of {} rows.\".format(df.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gender', 0),\n",
       " ('SeniorCitizen', 0),\n",
       " ('Partner', 0),\n",
       " ('Dependents', 0),\n",
       " ('tenure', 0),\n",
       " ('PhoneService', 0),\n",
       " ('MultipleLines', 0),\n",
       " ('InternetService', 0),\n",
       " ('OnlineSecurity', 0),\n",
       " ('OnlineBackup', 0),\n",
       " ('DeviceProtection', 0),\n",
       " ('TechSupport', 0),\n",
       " ('StreamingTV', 0),\n",
       " ('StreamingMovies', 0),\n",
       " ('Contract', 0),\n",
       " ('PaperlessBilling', 0),\n",
       " ('PaymentMethod', 0),\n",
       " ('MonthlyCharges', 0),\n",
       " ('TotalCharges', 11),\n",
       " ('Churn', 0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(c, df.where(col(c).isNull()).count()) for c in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 11 missing values in `TotalCharges`. Let's fill them with 0 since they seem to be new customers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an RFormula that uses all of the columns as features and call it `supervised`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the RFormula transformer and call it `fittedRF`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `fittedRF` transform our `df` DataFrame. Call this `preparedDF`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first couple of rows of `preparedDF`, with the truncate option off:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will retrieve the name of the columns used to make our feature vector and store them in a pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the transformed data into `train` and `test`. Use a 30% split and a `seed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate an instance of `LogisticRegression`. Call it `lr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the parameters of `lr` to check the default values used. You can always come back to the cell above and change the default values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model on `train` and call it `lrModel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we plot the coefficients of our model in a sorted fashion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance\n",
    "\n",
    "We already retrieved the name of the features. Let's join it with the coefficients to identify the ones with bigger absolute value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our fitted model, `lrModel`, extract the summary and call it `summary`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From `summary` extract `areaUnderROC`. Note that this AUC is from the `train` dataset and we should pay more attention to the AUC coming from the `test` set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From `summary` extract `roc` and convert it to a pandas DataFrame. Call it `roc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the `roc` DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same with `pr` from `summary`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline model looks promising. Let's do some predictions on the `test` set.\n",
    "\n",
    "Pass the `test` set through our trained model. Called the resulting DataFrame `fittedTest`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first few rows of this DataFrame. Only show the following columns: \"label\", \"prediction\", \"rawPrediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an evaluator from `BinaryClassificationEvaluator` function that calculates AUC. We will use this function to measure our model's performance on the `test` set. Call this evaluator `aucEvaluator`. \n",
    "\n",
    "Note that this function can be found under the `pyspark.ml.evaluation` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our `aucEvaluator` find out the AUC on the `test` set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are your test and train AUC's within the same range?\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "How can you improve this \"baseline\" model? We barely customized our model or features. Think about the ways you can improve the AUC. \n",
    "\n",
    "* Can you use pipeline API and create a grid search to tune the hyperparameters? \n",
    "* What are the hyperparameters that you would modify?\n",
    "* Try different regularization techniques by changing `elasticNetParam`. How does it impact our prediction power?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}